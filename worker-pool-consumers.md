# Auto-Scaling Workers - Deep Dive

## Why Auto-Scaling?

### The Problem with Fixed Workers

**Scenario 1: Low Load**

```
50 workers, 5 messages in queue
âŒ 45 workers sitting idle (wasted memory: ~90MB)
âŒ 45 goroutines doing nothing
```

**Scenario 2: High Load**

```
50 workers, 10,000 messages in queue
âŒ Queue growing faster than processing
âŒ Need more workers but stuck at 50
```

### The Solution: Dynamic Scaling

```
Low load:  2 workers  â†’ Uses 4MB RAM
High load: 50 workers â†’ Uses 100MB RAM, then scales back down
```

**Benefits:**

- ðŸ’° **Save resources** when idle
- ðŸš€ **Handle spikes** automatically
- âš¡ **Respond to demand** in real-time

## How Auto-Scaling Works

### Architecture

```
RabbitMQ â†’ Message Dispatcher â†’ Internal Queue (taskChan)
                                        â†“
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Worker Pool     â”‚
                              â”‚  (Dynamic Size)   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Auto-Scaler     â”‚
                              â”‚  (Monitors Load)  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

1. **Message Dispatcher**

   - Receives from RabbitMQ
   - Puts messages in internal buffered channel
   - Non-blocking

2. **Worker Pool**

   - Dynamic number of goroutines (min to max)
   - Workers pull from internal channel
   - Auto-terminate when idle too long

3. **Auto-Scaler**
   - Runs every 5 seconds
   - Monitors queue length and worker status
   - Spawns or terminates workers

## Scaling Logic

### Scale-Up Triggers

```go
if queueLen > 10 && activeWorkers < maxWorkers {
    // Queue is building up, need more workers!
    workersNeeded = queueLen / 5  // 1 worker per 5 messages
    spawn(workersNeeded)
}
```

**Example:**

```
Queue: 50 messages, Workers: 5
â†’ Spawn 10 workers (50 Ã· 5 = 10)
â†’ New total: 15 workers
```

### Scale-Down Triggers

```go
if idleWorkers > minWorkers && activeWorkers > minWorkers {
    // Too many workers sitting idle
    // Workers auto-terminate after 30s idle
}
```

**Example:**

```
Active: 20 workers, Idle: 15 workers, Min: 2
â†’ 13 workers will self-terminate after 30s idle
â†’ New total: ~7 workers (2 min + 5 busy)
```

## Worker Lifecycle

```
   Worker Spawned
        â†“
   [IDLE] â† â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”
        â†“                  â”‚
   Wait for message        â”‚
        â†“                  â”‚
   Message arrives         â”‚
        â†“                  â”‚
   [BUSY]                  â”‚
        â†“                  â”‚
   Process PDF             â”‚
        â†“                  â”‚
   Complete                â”‚
        â†“                  â”‚
   Return to [IDLE] â”€ â”€ â”€ â”˜
        â†“
   30s timeout?
        â†“
   activeWorkers > minWorkers?
        â†“
   YES â†’ Terminate
   NO  â†’ Stay alive
```

## Real-World Behavior

### Morning Rush (0 â†’ 1000 messages/min)

```
00:00 - Start: 2 workers (min)
      âœ… Processed: 0

00:05 - Queue: 100 messages
      ðŸ“ˆ SCALE UP: Spawn 20 workers
      Active: 22 workers
      âœ… Processed: 50

00:10 - Queue: 200 messages (still incoming fast)
      ðŸ“ˆ SCALE UP: Spawn 20 workers
      Active: 42 workers
      âœ… Processed: 450

00:15 - Queue: 50 messages (catching up)
      Active: 42 workers
      âœ… Processed: 1200

00:20 - Queue: 0 messages
      Active: 42 workers (all idle)
      âœ… Processed: 1500

00:25 - Workers timing out
      ðŸ“‰ SCALE DOWN: 30 workers terminated
      Active: 12 workers
      âœ… Processed: 1500

00:30 - More workers timing out
      ðŸ“‰ SCALE DOWN: 10 workers terminated
      Active: 2 workers (back to min)
      âœ… Processed: 1500
```

### Configuration Parameters

```go
type AutoScalingConsumer struct {
    minWorkers         int           // Always keep this many alive
    maxWorkers         int           // Never exceed this
    scaleUpThreshold   int           // Messages to trigger scale-up
    scaleDownIdle      time.Duration // Idle timeout before worker exits
    checkInterval      time.Duration // How often to evaluate scaling
}
```

**Tuning Guide:**

| Scenario       | minWorkers | maxWorkers | scaleUpThreshold | scaleDownIdle |
| -------------- | ---------- | ---------- | ---------------- | ------------- |
| Low traffic    | 1          | 10         | 5                | 30s           |
| Medium traffic | 5          | 50         | 10               | 60s           |
| High traffic   | 10         | 200        | 20               | 120s          |
| Bursty traffic | 2          | 100        | 5                | 30s           |
| Steady load    | 20         | 30         | 15               | 300s          |

## Running the Auto-Scaler

### Basic Usage

```bash
# Default: min=2, max=50
go run consumer/main.go

# Custom configuration
MIN_WORKERS=5 MAX_WORKERS=100 go run consumer/main.go
```

### Testing Scaling Behavior

```bash
# Terminal 1: Start consumer
go run consumer/main.go

# Terminal 2: Send burst of messages
for i in {1..100}; do
    go run producer/main.go &
done

# Watch the logs:
# ðŸ“ˆ SCALE UP: Queue has 80 messages, spawning 16 workers
# ðŸ‘· Worker 3 started
# ðŸ‘· Worker 4 started
# ...
# ðŸ“‰ SCALE DOWN: 10 workers idle, removing 8 workers
# ðŸ‘· Worker 15 stopped (idle timeout)
```

### Expected Output

```
ðŸš€ Auto-scaling consumer started
ðŸ“Š Min workers: 2, Max workers: 50
ðŸ‘· Worker 1 started
ðŸ‘· Worker 2 started

ðŸ“Š ==================== Stats ====================
   ðŸ‘· Active Workers: 2 (idle: 2, busy: 0)
   ðŸ“¦ Internal Queue: 0 messages
   âœ… Processed: 0
   âŒ Failed: 0
ðŸ“Š ===============================================

... messages arrive ...

ðŸ“ˆ SCALE UP: Queue has 45 messages, spawning 9 workers (active: 2 -> 11)
ðŸ‘· Worker 3 started
ðŸ‘· Worker 4 started
...
âœ… Worker 3: Completed pdf-001 in 4.2s
âœ… Worker 5: Completed pdf-002 in 3.8s

ðŸ“Š ==================== Stats ====================
   ðŸ‘· Active Workers: 11 (idle: 3, busy: 8)
   ðŸ“¦ Internal Queue: 12 messages
   âœ… Processed: 33
   âŒ Failed: 2
ðŸ“Š ===============================================

... queue cleared ...

ðŸ‘· Worker 10 stopped (idle timeout, active: 7)
ðŸ‘· Worker 9 stopped (idle timeout, active: 6)

ðŸ“‰ SCALE DOWN: 4 workers idle, removing 3 workers (active: 5 -> 2)

ðŸ“Š ==================== Stats ====================
   ðŸ‘· Active Workers: 2 (idle: 2, busy: 0)
   ðŸ“¦ Internal Queue: 0 messages
   âœ… Processed: 100
   âŒ Failed: 3
ðŸ“Š ===============================================
```

## Advanced: Metrics-Based Scaling

For production, use actual RabbitMQ queue metrics:

```go
func (c *AutoScalingConsumer) getQueueDepth() (int, error) {
    // Query RabbitMQ Management API
    resp, err := http.Get("http://localhost:15672/api/queues/%2F/pdf_processing")
    if err != nil {
        return 0, err
    }
    defer resp.Body.Close()

    var queue struct {
        Messages int `json:"messages"`
    }

    json.NewDecoder(resp.Body).Decode(&queue)
    return queue.Messages, nil
}

func (c *AutoScalingConsumer) evaluateScaling() {
    queueDepth, _ := c.getQueueDepth()

    // Scale based on actual RabbitMQ queue, not internal buffer
    if queueDepth > c.scaleUpThreshold {
        c.scaleUp()
    }
}
```

## Comparison: Fixed vs Auto-Scaling

### Memory Usage Over 24 Hours

```
Fixed (50 workers):
RAM: â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ (100MB constant)

Auto-scaling (2-50 workers):
RAM: â–“â–“____â–“â–“â–“â–“â–“â–“â–“â–“____â–“â–“ (avg 40MB, peaks 100MB)
     â””â”€idleâ”€â”˜â””â”€busyâ”€â”˜â””â”€idleâ”€â”˜
```

**Savings: 60MB average = 60% reduction!**

### Response Time

```
Scenario: 1000 messages arrive suddenly

Fixed (10 workers):
  - Immediate processing: 10 messages/second
  - Time to clear: 100 seconds

Auto-scaling (2-50 workers):
  - 0-5s: 2 workers = 2 msg/sec (10 processed)
  - 5-10s: Scales to 20 workers = 20 msg/sec (100 processed)
  - 10-15s: Scales to 50 workers = 50 msg/sec (250 processed)
  - 15-27s: 50 workers clear remaining 640
  - Total time: 27 seconds

Fixed would take 100s, Auto-scaling takes 27s!
```

## Production Best Practices

1. **Set Reasonable Limits**

   ```go
   minWorkers: 5  // Don't go too low (startup cost)
   maxWorkers: 200 // Don't exceed your RAM/CPU
   ```

2. **Monitor Metrics**

   ```go
   - activeWorkers (current count)
   - queueDepth (messages waiting)
   - processingRate (msgs/second)
   - scaleUpEvents (how often scaling up)
   - scaleDownEvents (how often scaling down)
   ```

3. **Tune for Your Workload**

   - **Predictable load**: Narrow range (10-20 workers)
   - **Bursty traffic**: Wide range (2-100 workers)
   - **24/7 steady**: Higher minimum (20-50 workers)

4. **Add Cooldown Periods**

   ```go
   lastScaleUp := time.Now()

   if time.Since(lastScaleUp) < 30*time.Second {
       return // Don't scale too frequently
   }
   ```

5. **Graceful Degradation**
   ```go
   if activeWorkers == maxWorkers && queueDepth > 1000 {
       log.Warn("At max capacity, consider adding more consumer instances")
   }
   ```

## Summary

**Auto-scaling gives you:**

- âœ… **Lower costs** when idle (2 workers vs 50)
- âœ… **Better performance** during spikes (scales to 50+ automatically)
- âœ… **Automatic adaptation** to load patterns
- âœ… **Resource efficiency** (no waste)

**Trade-offs:**

- âš ï¸ More complex code
- âš ï¸ Scale-up delay (5-10 seconds)
- âš ï¸ Requires tuning for your workload

**Use fixed workers when:**

- Load is predictable and constant
- You need instant response (no scale-up delay)
- Simple > complex for your use case

**Use auto-scaling when:**

- Load varies throughout the day
- You want to optimize costs
- Handling unpredictable traffic spikes
- Processing millions of messages efficiently
